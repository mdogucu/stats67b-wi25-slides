---
title: "Continuous Random Variables"
author: "Dr. Mine Dogucu"
execute:
  echo: true
format: 
  revealjs:
    footer: "[stats4cs.com](https://stats4cs.com)"
    slide-number: true
    incremental: true
    theme: ["../templates/slide-style.scss"]
    logo: "https://www.stats4cs.com/img/logo.png"
    title-slide-attributes: 
      data-background-image: "https://www.stats4cs.com/img/logo.png"
      data-background-size: 5%
      data-background-position: 50% 85%
    include-after-body: "../templates/clean_title_page.html"
---

# Discrete Random Variables Review

## Discrete Random Variables

A **discrete random** variable has a countable number of possible numeric outcomes.

. . .

Probability mass function (pmf):

$P(X = x) = f(x)$

. . .

Cumulative distribution function (cdf):

$P(X \leq x) = F(x)$

. . .

$E(X) = \sum_{S} x f(x)$

. . .

$Var(X)= E(X^2) - [E(X)]^2$





## Bernoulli Distribution

If X is a random variable that takes value 1 with probability of success $\pi$ and 0 with probability $1-\pi$, then X follows a Bernoulli distribution.

$S = \{0, 1 \}$


$X \sim \text{Bernoulli} (\pi)$

. . .

$E(X) = \mu = \pi$

. . .

$Var(X)=\sigma^2 = \pi(1-\pi)$



## Geometric Distribution

Let X be the number of failures needed __before__ the first success is observed in independent trials. $X$ follows a geometric distribution

::::{.columns}

:::{.column}
$S = \{0, 1, 2, 3, 4, ...\}$

$X \sim \text{Geometric} (\pi)$

$f(x) = (1-\pi)^x(\pi)$  

$E(X)=\frac{1-\pi}{\pi}$

$Var(X) = \frac{1-\pi}{\pi^2}$

:::

:::{.column}
```{r eval = FALSE}
dgeom(x, prob) #pmf
```


```{r eval = FALSE}
pgeom(q, prob) #cdf
```
:::
::::




## Binomial Distribution

The random variable X represents the number of successes in $n$ trials where in independent trial the probability of success is $\pi$.

::::{.columns}

:::{.column}

$S = \{0, 1, ..., n \}$

$X\sim \text{Binomial}(n, \pi)$

$P(X = x) = f(x) = {n \choose x}\pi^{x} (1-\pi)^{n-x}$


$E(X) = n\pi$  


$Var(X) = n\pi(1-\pi)$

:::

:::{.column}

```{r eval = FALSE}
dbinom(x, size, prob) #pmf
```


```{r eval = FALSE}
pbinom(q, size, prob) #cdf
```

:::

::::


## Poisson Distribution

Let $X$ represent the number of occurrences of an event within a  __fixed__ time or space.

::::{.columns}

:::{.column}

$S = \{0, 1, 2, 3, 4, ...\}$


$X \sim Poisson (\lambda)$


$P(X = x) = f(x) =\frac{\lambda^x}{x!} e^{-\lambda}$ 



$E(X) = Var(X) = \lambda$

:::

:::{.column}

```{r eval = FALSE}
dpois(x, lambda) #pmf
```


```{r eval = FALSE}
ppois(q, lambda) #cdf
```

:::

::::

# Continuous Random Variables
## Continuous Random Variables

A continuous random variable $X$ would have a sample space ( $S_X$ ) that is uncountably infinite. 

. . .

Let X be the the proportion of bike owners on campus. Then $S_x = [0, 1]$.

. . .

Let Y be the the survival time after some surgery. Then $S_Y = [0, \infty)$.



## Probability Density Function (pdf) - $f(x)$

A probability __density__ function gives the relative likelihood of the continuous random variable within the sample space.

$$f(x) \geq0 \text{ for all } x \ \epsilon \ S_X$$

. . .

$$\int_{x \ \epsilon \ S_X} f(x)dx = 1$$

. . .

$$P(a \leq X \leq b) = \int_a^b f(x)dx$$

## Cumulative Distribution Function

Let $X$ be a continuous random variable. Then the cumulative distribution function $F(x) = P(x \leq X)$ defined as:


$$F(x) = P(x \leq X) = \int_{-\infty}^x f(t) dt$$

1. $\frac{d}{dx}F = f$
2. $P(a \leq X \leq b) = F (b)− F(a)$
3. $P(X \geq a)= 1 − F (a) = \int_a^\infty f (x)dx$

## Example - pdf

:::: {.columns}

:::{.column}
```{r echo = FALSE, fig.align = 'center', out.width ="90%"}
knitr::include_graphics("img/cont_f.png")
```
:::

:::{.column}
```{r echo = FALSE, message = FALSE, fig.align="center", fig.height =4}
library(tidyverse)
theme_set(theme_gray(base_size = 22))

x <- seq(0,1, by = 0.1)


y <- 12*(x^2)*(1-x)

data <- data.frame(x = x,
                   y = y)

ggplot(data = data.frame(x = c(0, 1)), aes(x)) +
  stat_function(fun = function(x){12*(x^2)*(1-x)}) +
  labs(y = "f(x)")



```
:::

::::



. . .

$x^2 \geq0$

. . .

$(1-x) \geq0$


. . .

`r fontawesome::fa(name = "check")` $f(x) \geq0 \text{ for all } x \ \epsilon \ S_X$  


## Area Under the Curve = 1

::::{.columns}

:::{.column}
```{r echo = FALSE, fig.align = 'center', out.width ="90%"}
knitr::include_graphics("img/cont_f.png")
```
:::

:::{.column}

```{r echo = FALSE, message = FALSE, fig.align="center", fig.height =4}
theme_set(theme_gray(base_size = 22))

x <- seq(0,1, by = 0.001)


y <- 12*(x^2)*(1-x)

data <- data.frame(x = x,
                   y = y)

pdf<-function(x){12*(x^2)*(1-x)}

ggplot(data = data.frame(x = c(0, 1)), aes(x)) +
  stat_function(fun = pdf) +
  labs(y = "f(x)") +
 geom_segment(data = data, aes(x = x, y = 0, xend = x, yend = y), color = "#e56646") 


```
:::

::::

. . .

$\int_0^1 12(x^2)(1-x)dx$

. . .

$12\int_0^1 (x^2-x^3)dx$ 

. . .

$12\big[\frac{x^3}{3} -\frac{x^4}{4}\bigg\rvert_0^1\big] = 1$

. . .

`r fontawesome::fa(name = "check")` $\int_{x \ \epsilon \ S_X} f(x)dx = 1$

## Probability is Area Under the Curve

::::{.columns}

:::{.column}
```{r echo = FALSE, message = FALSE, fig.align="center", fig.height =4}
theme_set(theme_gray(base_size = 22))

x <- seq(0.25,0.5, by = 0.001)


y <- 12*(x^2)*(1-x)

data <- data.frame(x = x,
                   y = y)

pdf<-function(x){12*(x^2)*(1-x)}

ggplot(data = data.frame(x = c(0, 1)), aes(x)) +
  stat_function(fun = pdf) +
  labs(y = "f(x)") +
 geom_segment(data = data,
              aes(x = x, 
                    y = 0, 
                    xend = x, 
                    yend = y), 
              color = "#e56646") 





```
:::

:::{.column}
```{r echo = FALSE, fig.align = 'center', out.width ="90%"}
knitr::include_graphics("img/cont_f.png")
```
:::

::::


$P(0.25<X<0.50) = \int_{0.25}^{0.50} 12(x^2)(1-x)dx =12\int_{0.25}^{0.50} (x^2-x^3)dx$ 

. . .

$=12\big[\frac{x^3}{3} -\frac{x^4}{4}\bigg\rvert_{0.25}^{0.50}\big] = 0.2617188$

. . .

`r fontawesome::fa(name = "check")` $P(X\ \epsilon \ B) = \int_{x \ \epsilon \ B} f(x)dx$ 



## $P(X=x_i) = 0$



:::{.pull-right}

```{r echo = FALSE, fig.align = 'center', out.width ="90%"}
knitr::include_graphics("img/cont_f.png")
```

```{r echo = FALSE, message = FALSE, fig.align="center", fig.height =4}
theme_set(theme_gray(base_size = 22))

x <- seq(0.4,0.4, by = 0.001)


y <- 12*(x^2)*(1-x)

data <- data.frame(x = x,
                   y = y)

pdf<-function(x){12*(x^2)*(1-x)}

ggplot(data = data.frame(x = c(0, 1)), aes(x)) +
  stat_function(fun = pdf) +
  labs(y = "f(x)") +
 geom_segment(data = data,
              aes(x = x, 
                    y = 0, 
                    xend = x, 
                    yend = y), 
              color = "#e56646") 





```
:::

$P(X=0.40) =$ 

$\int_{0.40}^{0.40} 12(x^2)(1-x)dx$

. . .

$12\int_{0.40}^{0.40} (x^2-x^3)dx$ 

. . .

$12\big[\frac{x^3}{3} -\frac{x^4}{4}\bigg\rvert_{0.40}^{0.40}\big] = 0$

. . .

## cdf


:::{.pull-right}
```{r echo = FALSE, fig.align = 'center', out.width ="90%"}
knitr::include_graphics("img/cont_f.png")
```

```{r echo = FALSE, message = FALSE, fig.align="center", fig.height =4}
theme_set(theme_gray(base_size = 22))

x <- seq(0,0.7, by = 0.001)


y <- 12*(x^2)*(1-x)

data <- data.frame(x = x,
                   y = y)

pdf<-function(x){12*(x^2)*(1-x)}

ggplot(data = data.frame(x = c(0, 1)), aes(x)) +
  stat_function(fun = pdf) +
  labs(y = "f(x)") +
 geom_segment(data = data,
              aes(x = x, 
                    y = 0, 
                    xend = x, 
                    yend = y), 
              color = "#e56646") 





```
:::


$P(X\leq x) = \int_{-\infty}^x f(t)dt$ 


$P(X\leq 0.70) =$ 

$\int_{0}^{0.70} 12(t^2)(1-t)dt$

. . .

$12\big[\frac{t^3}{3} -\frac{t^4}{4}\bigg\rvert_{0}^{0.70}\big] = 0.6516996$

. . .

Note: $f(x) = \frac{dF(x)}{dx}$



## Expected Value

$E(X) = \int_{x \ \epsilon \ S_X} xf(x)dx$

. . .

$\int_0^1 x12(x^2)(1-x)dx$

. . .

$12\int_0^1 (x^3-x^4)dx$ 

. . .

$12\big[\frac{x^4}{4} -\frac{x^5}{5}\bigg\rvert_0^1\big] = 0.6$


## Variance

$Var(X) = E(X^2)- [E(X)]^2$

. . .

$E(X^2) = ?$

. . .

$E(X^2) = \int_0^1 x^212(x^2)(1-x)dx$

. . .

$E(X^2) = 12\int_0^1 (x^4-x^5)dx$ 

. . .

$E(X^2) = 12\big[\frac{x^5}{5} -\frac{x^6}{6}\bigg\rvert_0^1\big] = 0.4$

. . .

$Var(X) = 0.4- 0.6^2 = 0.04$



