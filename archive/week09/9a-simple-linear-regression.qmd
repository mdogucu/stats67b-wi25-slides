---
title: "Simple Linear Regression"
author: "Dr. Mine Dogucu"
execute:
  echo: true
format: 
  revealjs:
    footer: "[stats4cs.com](https://stats4cs.com)"
    slide-number: true
    incremental: true
    theme: ["../templates/slide-style.scss"]
    logo: "https://www.stats4cs.com/img/logo.png"
    title-slide-attributes: 
      data-background-image: "https://www.stats4cs.com/img/logo.png"
      data-background-size: 5%
      data-background-position: 50% 85%
    include-after-body: "../templates/clean_title_page.html"
---

## 

```{r}
#| echo: false
options(scipen=999)
library(tidyverse)
library(openintro)
library(broom)
theme_set(theme_bw(base_size = 22))
```

## Data `babies` in `openintro` package

```{r echo = FALSE}

glimpse(babies)

```

##  Baby Weights


```{r}
#| output-location: column

ggplot(babies, 
       aes(x = gestation, y = bwt)) +
  geom_point()

```


##  Baby Weights


```{r }
#| output-location: column

ggplot(babies,
       aes(x = gestation, y = bwt)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) 

```

`lm` stands for linear model  
`se` stands for standard error


## 

<center>



| y | Response    | Birth weight | Numeric |
|---|-------------|-----------------|---------|
| x | Explanatory | Gestation           | Numeric |

</center>


## Linear Equations Review


:::{.pull-left}

Recall from your previous math classes

$y = mx + b$

where $m$ is the slope and $b$ is the y-intercept

e.g. $y = 2x -1$
:::

. . .



:::{.pull-right}

```{r echo = FALSE, fig.height = 5, message = FALSE}
x <- c(0, 1, 2, 3, 4, 5)
y <- c(-1, 1, 3, 5, 7, 9)

as.data.frame(x = x, y = y) %>% 
  ggplot() +
  aes(x = x, y = y) +
  geom_point() +
  scale_y_continuous(breaks = c(-1, 1, 3, 5, 7, 9)) +
  scale_x_continuous(breaks = c(0, 1, 2, 3, 4, 5)) +
  geom_smooth(method = "lm", se = FALSE)

```

Notice anything different between baby weights plot and this one?
:::

##

:::{.pull-left}

**Math** class

$y = b + mx$

$b$ is y-intercept  
$m$ is slope  
:::


:::{.pull-left}

**Stats** class

$y_i = \beta_0 +\beta_1x_i + \epsilon_i$

$\beta_0$ is y-intercept  
$\beta_1$ is slope  
$\epsilon_i$ is error/residual  
$i = 1, 2, ...n$ identifier for each point
:::


## Notation

<table align ="center">

<thead>
<th> </th>
<th>Sample Statistic</th>
<th>Population Parameter</th>
</thead>

<tr>
<td>Intercept</td>
<td> $b_0$ </td>
<td> $\beta_0$</td>

</tr>

<tr>
<td> Slope </td>
<td> $b_1$ </td>
<td> $\beta_1$</td>

</tr>

<tr>
<td> Error/Residual </td>
<td> $e$ </td>
<td> $\epsilon$</td>

</tr>



</table>



##

```{r}
model_g <- lm(bwt ~ gestation, data = babies)

```

`lm` stands for linear model. We are fitting a linear regression model. Note that the variables are entered in y ~ x order.




##

```{r}
broom::tidy(model_g)
```

. . .

$\hat {y}_i = b_0 + b_1 x_i$

$\hat {\text{bwt}_i} = b_0 + b_1 \text{ gestation}_i$

$\hat {\text{bwt}_i} = -10.1 + 0.464\text{ gestation}_i$


## Expected bwt for a baby with 300 days of gestation

$\hat {\text{bwt}_i} = -10.1 + 0.464\text{ gestation}_i$

$\hat {\text{bwt}} = -10.1 + 0.464 \times 300$

$\hat {\text{bwt}} =$ `r -10.1 + 0.464*300`


For a baby with 300 days of gestation the expected birth weight is `r -10.1 + 0.464*300` ounces.



## Interpretation of estimates

:::{.pull-left}
```{r echo = FALSE, fig.align='center', message=FALSE, warning = FALSE, fig.height = 4}
babies %>% 
  ggplot() +
  aes(x = gestation, y = bwt) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) 
    
```

$b_1 = 0.464$ which means for one unit(day) increase in gestation period the expected increase in birth weight is 0.464 ounces.

:::

. . .

:::{.pull-right}
```{r echo = FALSE, fig.align='center', message=FALSE, warning = FALSE, fig.height = 4}
babies %>% 
  ggplot() +
  aes(x = gestation, y = bwt) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  xlim(0, 360) +
  ylim(-10, 180) +
  geom_abline(slope = 0.459, intercept = -8.76)
  
  
```

$b_0 = -10.1$ which means for gestation period of 0 days the expected birth weight is -10.1 ounces!!!!!!!!
(does NOT make sense)
:::



## Extrapolation

- There is no such thing as 0 days of gestation.

. . .

- Birth weight cannot possibly be -10.1 ounces.

. . .

- Extrapolation happens when we use a model outside the range of the x-values that are observed. After all, we cannot really know how the model behaves (e.g. may be non-linear) outside of the scope of what we have observed. 


## Baby number 148

:::{.pull-left}

```{r}
babies %>% 
  filter(case == 148) %>% 
  select(bwt, gestation)

```

:::

:::{.pull-right}

```{r echo = FALSE, message = FALSE, fig.height=5, warning = FALSE}

baby_148 <- subset(babies, case == 148)

babies %>% 
  ggplot() +
  aes(x = gestation, y = bwt) +
  geom_point(alpha = 0.1) +
  geom_smooth(method = "lm", se = FALSE) +
  geom_point(data = baby_148, color = "red")
```


:::



## Baby #148

:::{.pull-left}

**Expected**

$\hat y_{148} = b_0 +b_1x_{148}$

$\hat y_{148} = -10.1 + 0.464\times300$

$\hat y_{148}$ = `r -10.1 + 0.464*300`


:::

:::{.pull-left}

**Observed**

$y_{148} =$ 160

:::



## Residual for `i = 148`

:::{.pull-left}

```{r echo = FALSE, fig.align='center', message=FALSE, warning = FALSE, fig.height = 4}
babies %>% 
  ggplot() +
  aes(x = gestation, y = bwt) +
  geom_point(alpha = 0.1) +
  geom_smooth(method = "lm", se = FALSE) +
  geom_point(data = baby_148, color = "red") +
  geom_segment(x = 300, xend = 300, y = 128.94, yend = 160, color = "red")
```



:::

:::{.pull-right}

$y_{148} = 160$

$\hat y_{148}$ = `r -10.1 + 0.464*300`

$e_{148} = y_{148} - \hat y_{148}$

$e_{148} =$ `r 160 -(-10.1 + 0.464*300)`


:::



## Least Squares Regression 

The goal is to minimize 

$$e_1^2 + e_2^2 + ... + e_n^2$$

. . .

which can be rewritten as 

$$\sum_{i = 1}^n e_i^2$$

# Conditions

## Conditions for Least Squares Regression

- Linearity

- Normality of Residuals 

- Constant Variance

- Independence


##

:::{.pull-left}

**Linear**
```{r  echo = FALSE, message = FALSE}
set.seed(84735)
x <- seq(-2, 2, by = 0.01)
y <- 4*x + 5 + rnorm(length(x), 0 , 1.5)

data_good <- data.frame(x = x, y = y) %>%   sample_n(50)

data_good %>% 
  ggplot() +
  aes(x = x, y = y) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)
```

:::

:::{.pull-right}

**Non-linear**

```{r  echo = FALSE, message = FALSE}
set.seed(84735)
x <- seq(-2, 2, by = 0.01)
y <- 3*x^2 + x + 5 + rnorm(length(x), 0 , 2)

data_bad<- data.frame(x = x, y = y) %>% sample_n(50)

data_bad %>% 
  ggplot() +
  aes(x = x, y = y) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  stat_function(fun = function(x)3*x^2 + x + 5 )
```

:::


##

:::{.pull-left}

**Nearly normal**

```{r echo = FALSE, message = FALSE}
model_good <- lm(y ~ x, data = data_good)

data_good <- 
  data_good %>%
  sample_n(50) %>% 
  modelr::add_residuals(model_good) 

data_good %>% 
  ggplot(aes(x = resid)) +
  geom_density()

```

:::

:::{.pull-right}

**Not normal**


```{r echo = FALSE, message = FALSE}
model_bad <- lm(y ~ x, data = data_bad)

data_bad <- 
  data_bad %>% 
  modelr::add_residuals(model_bad) 

data_bad %>% 
  ggplot(aes(x = resid)) +
  geom_density()

```

:::

##

:::{.pull-left}

**Constant Variance**

```{r echo = FALSE, message = FALSE}

data_good %>% 
  ggplot(aes(x = x, y = resid)) +
  geom_point() +
  geom_hline(yintercept = 0)

```

:::

:::{.pull-right}

**Non-constant variance**


```{r echo = FALSE, message = FALSE}


data_bad %>% 
  ggplot(aes(x = x, y = resid)) +
  geom_point() +
  geom_hline(yintercept = 0)

```

:::


## Independence

Harder to check because we need to know how the data were collected.

. . .

In the description of the dataset it says _[a study]considered all pregnancies between 1960 and 1967 among women in the Kaiser Foundation Health Plan in the San Francisco East Bay area._

. . .

It is possible that babies born in the same hospital may have similar birth weight. 


##

Correlated data examples: patients within hospitals, students within schools, people within neighborhoods, time-series data.

# Inference

## Inference: Hypothesis Testing

```{r}
#| echo: false
g_summary <- tidy(model_g)
```

$H_o: \beta_1 = 0$

$H_A: \beta_1 \neq 0$

. . .

```{r}
tidy(model_g)
```

Since the p-value of 3.22e-50 < 0.05 we reject the null hypothesis and conclude that there is a significant relationship between gestation and birth weight. 

## Inference: Confidence Interval

CI = point estimate $\pm$ critical value $\times$ standard error

95% CI for the slope =  point estimate of the slope $\pm$ critical value $\times$ standard error of the slope

Critical value 

```{r}
qt(0.975, df = 1235) # recall n = 1236
```
```{r}
#| echo: false
cv <- qt(0.975, df = 1235) # recall n = 1236
```

## Inference: Confidence Interval

```{r}
tidy(model_g)
```


95% CI = `r g_summary[2,2]`	$\pm$ `r cv` $\times$ `r g_summary[2,3]`

95% CI = (`r g_summary[2,2]-cv*g_summary[2,3]`, `r g_summary[2,2]+cv*g_summary[2,3]`)

## Inference: Confidence Interval

```{r}
tidy(model_g)
```


## Inference: Confidence Interval

```{r}
confint(model_g)
```

Note that the 95% confidence interval for the slope does not contain zero and all the values in the interval are positive indicating a significant positive relationship between gestation and birth weight.

## Confidence Interval

##

| y | Response    | Birth weight | Numeric |
|---|-------------|-----------------|---------|
| x | Explanatory | Smoke           | Categorical |




## Notation

$y_i = \beta_0 +\beta_1x_i + \epsilon_i$

$\beta_0$ is y-intercept  
$\beta_1$ is slope  
$\epsilon_i$ is error/residual  
$i = 1, 2, ...n$ identifier for each point


##

```{r}
model_s <- lm(bwt ~ smoke, data = babies)
tidy(model_s)
```




$\hat {y}_i = b_0 + b_1 x_i$

$\hat {\text{bwt}_i} = b_0 + b_1 \text{ smoke}_i$

$\hat {\text{bwt}_i} = 123 + (-8.94\text{ smoke}_i)$

##

:::{.pull-left}

Expected bwt for a baby with a non-smoker mother

$\hat {\text{bwt}_i} = 123 + (-8.94\text{ smoke}_i)$

$\hat {\text{bwt}_i} = 123 + (-8.94\times 0)$

$\hat {\text{bwt}_i} = 123$

$E[bwt_i | smoke_i = 0] = b_0$


:::

:::{.pull-right}

Expected bwt for a baby with a smoker mother

$\hat {\text{bwt}_i} = 123 + (-8.94\text{ smoke}_i)$

$\hat {\text{bwt}_i} = 123 + (-8.94\times 1)$

$\hat {\text{bwt}_i} = 114.06$

$E[bwt_i | smoke_i = 1] = b_0 + b_1$

:::

##

```{r}
confint(model_s)
```

Note that the confidence interval for the "slope" does not contain 0 and all the values in the interval are negative. 


## Understanding Relationships

- Just because we observe a significant relationship between $x$ and $y$, it does not mean that $x$ causes $y$.

- Just because we observe a significant relationship in a sample that does not mean the findings will generalize to the population. 

- For these we need to understand sampling and study design. 